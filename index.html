<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>MorphCast Video Emotion Tracking</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 0;
      padding: 0;
    }
    video {
      width: 100%;
      max-width: 600px; /* Ensures video scales on large and small devices */
      height: auto;
      margin-top: 20px;
    }
    button {
      padding: 10px 20px;
      font-size: 16px;
      background-color: #4CAF50;
      color: white;
      border: none;
      cursor: pointer;
      border-radius: 5px;
      margin: 10px;
    }
    #buttonContainer {
      margin: 20px 0;
    }
  </style>
</head>
<body>

  <h1>Watch the Video and Track Your Emotions</h1>

  <div id="buttonContainer">
    <button id="watchBtn">Watch Video</button>
    <button id="privacyBtn">Privacy Policy</button>
  </div>

  <div id="videoContainer">
    <video id="videoPlayer" controls>
      <source src="https://assets.homa-cloud.com/clicqla3j02wfyq01nkyf7621/853d663c-39ba-4755-bf72-1da193d2e2d4/HIR_C67_V4_WW_VID_1080x1920_33s.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>

  <button onclick="downloadCSV()">Download CSV</button>
  <button onclick="downloadJSON()">Download JSON</button>

  <script src="https://sdk.morphcast.com/mphtools/v1.1/mphtools.js" data-config="cameraPrivacyPopup, compatibilityUI, compatibilityAutoCheck"></script>
  <script src="https://ai-sdk.morphcast.com/v1.16/ai-sdk.js"></script>
  <script src="https://sdk.morphcast.com/emotion-statistics/v1.0-beta/script.js"></script>

  <script>
    let trackingData = [];

    const watchBtn = document.getElementById('watchBtn');
    const videoContainer = document.getElementById('videoContainer');
    const videoPlayer = document.getElementById('videoPlayer');

    const statsConfig = {
      sendDatainterval: 5000,
      tickInterval: 1000,
      stopAfter: 7200000,
      licenseKey: "sk9bebf5467e79a53a382ee56f1293c7e03b406b94f0af"
    };

    const statisticsUploader = new MorphCastStatistics.StatisticsUploader(statsConfig);

    // Load MorphCast AI modules
    let morphcastInstance = null;

    CY.loader()
      .licenseKey("sk9bebf5467e79a53a382ee56f1293c7e03b406b94f0af")
      .addModule(CY.modules().FACE_AROUSAL_VALENCE.name, { smoothness: 0.70 })
      .addModule(CY.modules().FACE_EMOTION.name, { smoothness: 0.40 })
      .addModule(CY.modules().FACE_ATTENTION.name, { smoothness: 0.83 })
      .addModule(CY.modules().FACE_DETECTOR.name, { maxInputFrameSize: 320, smoothness: 0.83 })
      .load()
      .then(({ start, stop }) => {
        morphcastInstance = { start, stop };
      });

    // When the watch button is clicked
    watchBtn.addEventListener('click', async () => {
      videoContainer.style.display = 'block'; // Show video

      if (morphcastInstance) {
        await morphcastInstance.start();
        await statisticsUploader.start();
      }

      // Open video in full-screen mode
      if (videoPlayer.requestFullscreen) {
        videoPlayer.requestFullscreen();
      } else if (videoPlayer.mozRequestFullScreen) {
        videoPlayer.mozRequestFullScreen(); // Firefox
      } else if (videoPlayer.webkitRequestFullscreen) {
        videoPlayer.webkitRequestFullscreen(); // Chrome, Safari and Opera
      } else if (videoPlayer.msRequestFullscreen) {
        videoPlayer.msRequestFullscreen(); // IE/Edge
      }

      videoPlayer.play(); // Play the video

      videoPlayer.onended = async () => {
        if (morphcastInstance) {
          await statisticsUploader.stop();
          await morphcastInstance.stop();
        }
        alert("Video ended. Emotion tracking stopped.");
      };
    });

// Collect data from all relevant MorphCast events

    // FACE_AROUSAL_VALENCE
    window.addEventListener(CY.modules().FACE_AROUSAL_VALENCE.eventName, (evt) => {
      let frameData = {
        mediaTime: videoPlayer.currentTime,
        type: 'FACE_AROUSAL_VALENCE',
        valence: evt.detail.output.valence,
        arousal: evt.detail.output.arousal
      };
      trackingData.push(frameData);
      console.log(frameData);
    });

    // FACE_EMOTION
    window.addEventListener(CY.modules().FACE_EMOTION.eventName, (evt) => {
      let frameData = {
        mediaTime: videoPlayer.currentTime,
        type: 'FACE_EMOTION',
        dominantEmotion: evt.detail.output.dominantEmotion,
        emotions: evt.detail.output.emotion
      };
      trackingData.push(frameData);
      console.log(frameData);
    });

    // FACE_ATTENTION
    window.addEventListener(CY.modules().FACE_ATTENTION.eventName, (evt) => {
      let frameData = {
        mediaTime: videoPlayer.currentTime,
        type: 'FACE_ATTENTION',
        attention: evt.detail.output.attention
      };
      trackingData.push(frameData);
      console.log(frameData);
    });

    // FACE_DETECTOR
    window.addEventListener(CY.modules().FACE_DETECTOR.eventName, (evt) => {
      let frameData = {
        mediaTime: videoPlayer.currentTime,
        type: 'FACE_DETECTOR',
        totalFaces: evt.detail.totalFaces,
        status: evt.detail.status
      };
      trackingData.push(frameData);
      console.log(frameData);
    });

    // ALARM_NO_FACE
    window.addEventListener(CY.modules().ALARM_NO_FACE.eventName, (evt) => {
      let frameData = {
        mediaTime: videoPlayer.currentTime,
        type: 'ALARM_NO_FACE',
        alarmTriggered: true
      };
      trackingData.push(frameData);
      console.log(frameData);
    });

    // DATA_AGGREGATOR
    window.addEventListener(CY.modules().DATA_AGGREGATOR.eventName, (evt) => {
      let frameData = {
        mediaTime: videoPlayer.currentTime,
        type: 'DATA_AGGREGATOR',
        aggregatedData: evt.detail.output
      };
      trackingData.push(frameData);
      console.log(frameData);
    });

   // Convert collected data to CSV
    function convertToCSV(data) {
      const headers = ['mediaTime', 'attention', 'dominantEmotion', 'arousal', 'valence', 'emotion'];
      const csvRows = [headers.join(',')];

      data.forEach(row => {
        csvRows.push([
          row.mediaTime, row.attention, row.dominantEmotion, row.arousal, row.valence, JSON.stringify(row.emotion)
        ].join(','));
      });

      return csvRows.join('\n');
    }

    function downloadCSV() {
      const csvData = convertToCSV(trackingData);
      const blob = new Blob([csvData], { type: 'text/csv' });
      const url = window.URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.style.display = 'none';
      a.href = url;
      a.download = 'emotion_tracking_report.csv';
      document.body.appendChild(a);
      a.click();
      window.URL.revokeObjectURL(url);
    }

    function downloadJSON() {
      const jsonData = JSON.stringify(trackingData, null, 2);
      const blob = new Blob([jsonData], { type: 'application/json' });
      const url = window.URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.style.display = 'none';
      a.href = url;
      a.download = 'emotion_tracking_report.json';
      document.body.appendChild(a);
      a.click();
      window.URL.revokeObjectURL(url);
    }
  </script>

</body>
</html>
